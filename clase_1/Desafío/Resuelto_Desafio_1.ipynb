{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq6j8LsYq1Dr"
      },
      "source": [
        "### Vectorización de texto y modelo de clasificación Naïve Bayes con el dataset 20 newsgroups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "l7cXR6CI30ry"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 20newsgroups por ser un dataset clásico de NLP ya viene incluido y formateado\n",
        "# en sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-pVDWV_rQc"
      },
      "source": [
        "## Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ech9qJaUo9vK"
      },
      "outputs": [],
      "source": [
        "# cargamos los datos (ya separados de forma predeterminada en train y test)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxjSI7su_uWI"
      },
      "source": [
        "## Vectorización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-94VP0QYCzDn"
      },
      "outputs": [],
      "source": [
        "# instanciamos un vectorizador\n",
        "# ver diferentes parámetros de instanciación en la documentación de sklearn\n",
        "tfidfvect = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "ftPlyanuak8n",
        "outputId": "45a94d0e-49e7-4f7c-c806-7d5b66779dd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[...]\n",
            "\n",
            "These don't seem like \"little things\" to me.  At least, they are orders\n",
            "worse than the motto.  Do you think that the motto is a \"little thing\"\n",
            "that will lead to worse things?\n"
          ]
        }
      ],
      "source": [
        "# en el atributo `data` accedemos al texto\n",
        "print(newsgroups_train.data[20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1zxcXV6aC_oL"
      },
      "outputs": [],
      "source": [
        "# con la interfaz habitual de sklearn podemos fitear el vectorizador\n",
        "# (obtener el vocabulario y calcular el vector IDF)\n",
        "# y transformar directamente los datos\n",
        "X_train = tfidfvect.fit_transform(newsgroups_train.data)\n",
        "# `X_train` la podemos denominar como la matriz documento-término"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sv7TXbda41-",
        "outputId": "dcca5de6-dac1-4d68-d284-ce7be2ed9e2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse._csr.csr_matrix'>\n",
            "shape: (11314, 101631)\n",
            "cantidad de documentos: 11314\n",
            "tamaño del vocabulario (dimensionalidad de los vectores): 101631\n"
          ]
        }
      ],
      "source": [
        "# recordar que las vectorizaciones por conteos son esparsas\n",
        "# por ello sklearn convenientemente devuelve los vectores de documentos\n",
        "# como matrices esparsas\n",
        "print(type(X_train))\n",
        "print(f'shape: {X_train.shape}')\n",
        "print(f'cantidad de documentos: {X_train.shape[0]}')\n",
        "print(f'tamaño del vocabulario (dimensionalidad de los vectores): {X_train.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgydNTZ2pAgR",
        "outputId": "95111464-e40c-4b57-d154-ede153739a82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25775"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# una vez fiteado el vectorizador, podemos acceder a atributos como el vocabulario\n",
        "# aprendido. Es un diccionario que va de términos a índices.\n",
        "# El índice es la posición en el vector de documento.\n",
        "tfidfvect.vocabulary_['car']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xnTSZuvyrTcP"
      },
      "outputs": [],
      "source": [
        "# es muy útil tener el diccionario opuesto que va de índices a términos\n",
        "idx2word = {v: k for k,v in tfidfvect.vocabulary_.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swa-AgWrMSHM",
        "outputId": "93d09f31-4c42-4215-e750-a13c83ecf96a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# en `y_train` guardamos los targets que son enteros\n",
        "y_train = newsgroups_train.target\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je5kxvQMDLvf",
        "outputId": "59799046-9799-406f-c4be-81c5765de58d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "clases [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hay 20 clases correspondientes a los 20 grupos de noticias\n",
        "print(f'clases {np.unique(newsgroups_test.target)}')\n",
        "newsgroups_test.target_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXCICFSd_y90"
      },
      "source": [
        "## Similaridad de documentos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pki_olShnyE",
        "outputId": "b2bd8485-40c7-4923-c8a9-4ad6b735576e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE WHITE HOUSE\n",
            "\n",
            "                  Office of the Press Secretary\n",
            "                   (Pittsburgh, Pennslyvania)\n",
            "______________________________________________________________\n",
            "For Immediate Release                         April 17, 1993     \n",
            "\n",
            "             \n",
            "                  RADIO ADDRESS TO THE NATION \n",
            "                        BY THE PRESIDENT\n",
            "             \n",
            "                Pittsburgh International Airport\n",
            "                    Pittsburgh, Pennsylvania\n",
            "             \n",
            "             \n",
            "10:06 A.M. EDT\n",
            "             \n",
            "             \n",
            "             THE PRESIDENT:  Good morning.  My voice is coming to\n",
            "you this morning through the facilities of the oldest radio\n",
            "station in America, KDKA in Pittsburgh.  I'm visiting the city to\n",
            "meet personally with citizens here to discuss my plans for jobs,\n",
            "health care and the economy.  But I wanted first to do my weekly\n",
            "broadcast with the American people. \n",
            "             \n",
            "             I'm told this station first broadcast in 1920 when\n",
            "it reported that year's presidential elections.  Over the past\n",
            "seven decades presidents have found ways to keep in touch with\n",
            "the people, from whistle-stop tours to fire-side chats to the bus\n",
            "tour that I adopted, along with Vice President Gore, in last\n",
            "year's campaign.\n",
            "             \n",
            "             Every Saturday morning I take this time to talk with\n",
            "you, my fellow Americans, about the problems on your minds and\n",
            "what I'm doing to try and solve them.  It's my way of reporting\n",
            "to you and of giving you a way to hold me accountable.\n",
            "             \n",
            "             You sent me to Washington to get our government and\n",
            "economy moving after years of paralysis and policy and a bad\n",
            "experiment with trickle-down economics.  You know how important\n",
            "it is for us to make bold, comprehensive changes in the way we do\n",
            "business.  \n",
            "             \n",
            "             We live in a competitive global economy.  Nations\n",
            "rise and fall on the skills of their workers, the competitiveness\n",
            "of their companies, the imagination of their industries, and the\n",
            "cooperative experience and spirit that exists between business,\n",
            "labor and government.  Although many of the economies of the\n",
            "industrialized world are now suffering from slow growth, they've\n",
            "made many of the smart investments and the tough choices which\n",
            "our government has for too long ignored.  That's why many of them\n",
            "have been moving ahead and too many of our people have been\n",
            "falling behind.\n",
            "             \n",
            "             We have an economy today that even when it grows is\n",
            "not producing new jobs.  We've increased the debt of our nation\n",
            "by four times over the last 12 years, and we don't have much to\n",
            "show for it.  We know that wages of most working people have\n",
            "stopped rising, that most people are working longer work weeks\n",
            "and that too many families can no longer afford the escalating\n",
            "cost of health care.\n",
            "             \n",
            "             But we also know that, given the right tools, the\n",
            "right incentives and the right encouragement, our workers and\n",
            "businesses can make the kinds of products and profits our economy\n",
            "needs to expand opportunity and to make our communities better\n",
            "places to live.\n",
            "             \n",
            "             In many critical products today Americans are the\n",
            "low cost, high quality producers.  Our task is to make sure that\n",
            "we create more of those kinds of jobs.\n",
            "             \n",
            "             Just two months ago I gave Congress my plan for\n",
            "long-term jobs and economic growth.  It changes the old\n",
            "priorities in Washington and puts our emphasis where it needs to\n",
            "be -- on people's real needs, on increasing investments and jobs\n",
            "and education, on cutting the federal deficit, on stopping the\n",
            "waste which pays no dividends, and redirecting our precious\n",
            "resources toward investment that creates jobs now and lays the\n",
            "groundwork for robust economic growth in the future.\n",
            "             \n",
            "             These new directions passed the Congress in record\n",
            "time and created a new sense of hope and opportunity in our\n",
            "country.  Then the jobs plan I presented to Congress, which would\n",
            "create hundreds of thousands of jobs, most of them in the private\n",
            "sector in 1993 and 1994, passed the House of Representatives.  It\n",
            "now has the support of a majority of the United States Senate. \n",
            "But it's been held up by a filibuster of a minority in the\n",
            "Senate, just 43 senators.  They blocked a vote that they know\n",
            "would result in the passage of our bill and the creation of jobs.\n",
            "             \n",
            "             The issue isn't politics; the issue is people. \n",
            "Millions of Americans are waiting for this legislation and\n",
            "counting on it, counting on us in Washington.  But the jobs bill\n",
            "has been grounded by gridlock.  \n",
            "             \n",
            "             I know the American people are tired of business as\n",
            "usual and politics as usual.  I know they don't want us to spin\n",
            "or wheels.  They want the recovery to get moving.  So I have\n",
            "taken a first step to break this gridlock and gone the extra\n",
            "mile.  Yesterday I offered to cut the size of this plan by 25\n",
            "percent -- from $16 billion to $12 billion.  \n",
            "             \n",
            "             It's not what I'd hoped for.  With 16 million\n",
            "Americans looking for full-time work, I simply can't let the bill\n",
            "languish when I know that even a compromise bill will mean\n",
            "hundreds of thousands of jobs for our people.  The mandate is to\n",
            "act to achieve change and move the country forward.  By taking\n",
            "this initiative in the face of an unrelenting Senate talkathon, I\n",
            "think we can respond to your mandate and achieve a significant\n",
            "portion of our original goals.\n",
            "             \n",
            "             First, we want to keep the programs as much as\n",
            "possible that are needed to generate jobs and meet human needs,\n",
            "including highway and road construction, summer jobs for young\n",
            "people, immunization for children, construction of waste water\n",
            "sites, and aid to small businesses.  We also want to keep funding\n",
            "for extended unemployment compensation benefits, for people who\n",
            "have been unemployed for a long time because the economy isn't\n",
            "creating jobs.\n",
            "             \n",
            "             Second, I've recommended that all the other programs\n",
            "in the bill be cut across-the-board by a little more than 40\n",
            "percent.\n",
            "             \n",
            "             And third, I've recommended a new element in this\n",
            "program to help us immediately start our attempt to fight against\n",
            "crime by providing $200 million for cities and towns to rehire\n",
            "police officers who lost their jobs during the recession and put\n",
            "them back to work protecting our people.  I'm also going to fight\n",
            "for a tough crime bill because the people of this country need it\n",
            "and deserve it.\n",
            "             \n",
            "             Now, the people who are filibustering this bill --\n",
            "the Republican senators -- say they won't vote for it because it\n",
            "increases deficit spending, because there's extra spending this\n",
            "year that hasn't already been approved.  That sounds reasonable,\n",
            "doesn't it?  Here's what they don't say.  This program is more\n",
            "than paid for by budget cuts over my five-year budget, and this\n",
            "budget is well within the spending limits already approved by the\n",
            "Congress this year.\n",
            "             \n",
            "             It's amazing to me that many of these same senators\n",
            "who are filibustering the bill voted during the previous\n",
            "administration for billions of dollars of the same kind of\n",
            "emergency spending, and much of it was not designed to put the\n",
            "American people to work.  \n",
            "             \n",
            "             This is not about deficit spending.  We have offered\n",
            "a plan to cut the deficit.  This is about where your priorities\n",
            "are -- on people or on politics.  \n",
            "             \n",
            "             Keep in mind that our jobs bill is paid for dollar\n",
            "for dollar.  It is paid for by budget cuts.  And it's the\n",
            "soundest investment we can now make for ourselves and our\n",
            "children.  I urge all Americans to take another look at this jobs\n",
            "and investment program; to consider again the benefits for all of\n",
            "us when we've helped make more American partners working to\n",
            "ensure the future of our nation and the strength of our economy.\n",
            "             \n",
            "             You know, if every American who wanted a job had\n",
            "one, we wouldn't have a lot of the other problems we have in this\n",
            "country today.  This bill is not a miracle, it's a modest first\n",
            "step to try to set off a job creation explosion in this country\n",
            "again.  But it's a step we ought to take.  And it is fully paid\n",
            "for over the life of our budget.\n",
            "             \n",
            "             Tell your lawmakers what you think.  Tell them how\n",
            "important the bill is.  If it passes, we'll all be winners.\n",
            "             \n",
            "             Good morning, and thank you for listening.\n"
          ]
        }
      ],
      "source": [
        "# Veamos similaridad de documentos. Tomemos algún documento\n",
        "idx = 4811\n",
        "print(newsgroups_train.data[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ssa9bqJ-hA_v"
      },
      "outputs": [],
      "source": [
        "# midamos la similaridad coseno con todos los documentos de train\n",
        "cossim = cosine_similarity(X_train[idx], X_train)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_mDA7p3AzcQ",
        "outputId": "747a3923-4b1c-4e2b-921d-4ebf2b271b00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.        , 0.70930477, 0.67474953, ..., 0.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# podemos ver los valores de similaridad ordenados de mayor a menos\n",
        "np.sort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OIhDA1jAryX",
        "outputId": "04ddf3ca-0741-42d7-8bbb-00bb395f7834"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 4811,  6635,  4253, ...,  1534, 10055,  4750], dtype=int64)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y a qué documentos corresponden\n",
        "np.argsort(cossim)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hP7qLS4ZBLps"
      },
      "outputs": [],
      "source": [
        "# los 5 documentos más similares:\n",
        "mostsim = np.argsort(cossim)[::-1][1:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QdJLHPJACvaj",
        "outputId": "926186cf-7d4c-4bd3-927b-ad00bf7f24f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'talk.politics.misc'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el documento original pertenece a la clase:\n",
        "newsgroups_train.target_names[y_train[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWy_73epCbFG",
        "outputId": "daf534e5-b2a8-43d4-d05a-9c52b816cf69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n",
            "talk.politics.misc\n"
          ]
        }
      ],
      "source": [
        "# y los 5 más similares son de las clases:\n",
        "for i in mostsim:\n",
        "  print(newsgroups_train.target_names[y_train[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRoNnKwhBqzq"
      },
      "source": [
        "### Modelo de clasificación Naïve Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TPM0thDaLk0R",
        "outputId": "bc7fdc3e-d912-4e0c-9d9e-33efc97b46fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# es muy fácil instanciar un modelo de clasificación Naïve Bayes y entrenarlo con sklearn\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NrQjzM48Mu4T"
      },
      "outputs": [],
      "source": [
        "# con nuestro vectorizador ya fiteado en train, vectorizamos los textos\n",
        "# del conjunto de test\n",
        "X_test = tfidfvect.transform(newsgroups_test.data)\n",
        "y_test = newsgroups_test.target\n",
        "y_pred =  clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkGJhetEPdA4",
        "outputId": "232ee2ce-e904-466e-be57-babc1f319029"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5854345727938506"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# el F1-score es una metrica adecuada para reportar desempeño de modelos de claificación\n",
        "# es robusta al desbalance de clases. El promediado 'macro' es el promedio de los\n",
        "# F1-score de cada clase. El promedio 'micro' es equivalente a la accuracy que no\n",
        "# es una buena métrica cuando los datasets son desbalanceados\n",
        "f1_score(y_test, y_pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McArD4rSDR2K"
      },
      "source": [
        "### Consigna del desafío 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJgf6GQIIEH1"
      },
      "source": [
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación.\n",
        "\n",
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB.\n",
        "\n",
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Respuestas\n",
        "\n",
        "**1**. Vectorizar documentos. Tomar 5 documentos al azar y medir similaridad con el resto de los documentos.\n",
        "Estudiar los 5 documentos más similares de cada uno analizar si tiene sentido\n",
        "la similaridad según el contenido del texto y la etiqueta de clasificación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analizar_similitud_documentos(newsgroups_train, n_documentos=5, random_seed=42):\n",
        "\n",
        "     # Se fija la semilla para poder repetir el experimento y ver los mismos documentos.\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "    # Convertimos los textos a vectores TF-IDF\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    X_train = vectorizer.fit_transform(newsgroups_train.data)\n",
        "    \n",
        "    # Seleccionamos n documentos al azar\n",
        "    total_docs = len(newsgroups_train.data)\n",
        "    docs_aleatorios = random.sample(range(total_docs), n_documentos)\n",
        "    \n",
        "    resultados = {}\n",
        "    \n",
        "    for idx in docs_aleatorios:\n",
        "        # midamos la similaridad coseno con todos los documentos de train\n",
        "        similitudes = cosine_similarity(X_train[idx:idx+1], X_train).flatten()\n",
        "   \n",
        "        # Ordenamos los índices por similitud (excluyendo el documento mismo)\n",
        "        similitudes[idx] = -1  # Excluimos la auto-similitud\n",
        "        indices_ordenados = np.argsort(similitudes)[::-1][:5]  # Top 5 más similares\n",
        "        \n",
        "        resultados[idx] = {\n",
        "            'documento_original': newsgroups_train.data[idx][:200] + \"...\",  # Primeros 200 caracteres\n",
        "            'categoria': newsgroups_train.target_names[newsgroups_train.target[idx]],\n",
        "            'documentos_similares': [\n",
        "                {\n",
        "                    'indice': i,\n",
        "                    'similitud': similitudes[i],\n",
        "                    'categoria': newsgroups_train.target_names[newsgroups_train.target[i]],\n",
        "                    'texto': newsgroups_train.data[i][:200] + \"...\"\n",
        "                }\n",
        "                for i in indices_ordenados\n",
        "            ]\n",
        "        }\n",
        "    \n",
        "    return resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados = analizar_similitud_documentos(newsgroups_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Documento original N°10440 (Categoría: rec.sport.hockey):\n",
            "\n",
            "These new rule changes are great!  However, I think that your rules are\n",
            "MUCH too complicated.  How will the normal average fan be able to count\n",
            "how many fouls a player has?  And then we would even ha...\n",
            "\n",
            "***************** Documentos más similares: ****************\n",
            "\n",
            "DOCUMENTO SIMILAR: 1\n",
            "\n",
            "\tÍndice: 9434\n",
            "\tSimilitud: 0.3907\n",
            "\tCategoría: rec.sport.baseball\n",
            "\tTexto: \n",
            "\n",
            "What makes you think Buck will still be in New York at year's end with\n",
            "George back?  :-)\n",
            "\n",
            "--\n",
            "    Keith Keller\t\t\t\tLET'S GO RANGERS!!!!!\n",
            "\t\t\t\t\t\tLET'S GO QUAKERS!!!!!\n",
            "\tkkeller@mail.sas.upenn.edu\t\tIVY LE...\n",
            "\n",
            "DOCUMENTO SIMILAR: 2\n",
            "\n",
            "\tÍndice: 4837\n",
            "\tSimilitud: 0.3807\n",
            "\tCategoría: rec.sport.hockey\n",
            "\tTexto: \n",
            "I think that they go to divisional records before goals, but I could be\n",
            "wrong, too.\n",
            "\n",
            "--\n",
            "    Keith Keller\t\t\t\tLET'S GO RANGERS!!!!!\n",
            "\t\t\t\t\t\tLET'S GO QUAKERS!!!!!\n",
            "\tkkeller@mail.sas.upenn.edu\t\tIVY LEAGUE C...\n",
            "\n",
            "DOCUMENTO SIMILAR: 3\n",
            "\n",
            "\tÍndice: 1653\n",
            "\tSimilitud: 0.3698\n",
            "\tCategoría: rec.sport.hockey\n",
            "\tTexto: What's the deal?  c.s.h. has nothing on it yet.  Is it in OT, is it over,\n",
            "what?  I want to know!  We all want to know!  Where's Roger when you need\n",
            "him?!?!?!?!  :-)\n",
            "\n",
            "--\n",
            "    Keith Keller\t\t\t\tLET'S GO RA...\n",
            "\n",
            "DOCUMENTO SIMILAR: 4\n",
            "\n",
            "\tÍndice: 10162\n",
            "\tSimilitud: 0.3491\n",
            "\tCategoría: rec.sport.hockey\n",
            "\tTexto: Well, I will have to change the scoring on my playoff pool.  Unfortunately\n",
            "I don't have time right now, but I will certainly post the new scoring\n",
            "rules by tomorrow.  Does it matter?  No, you'll enter ...\n",
            "\n",
            "DOCUMENTO SIMILAR: 5\n",
            "\n",
            "\tÍndice: 2568\n",
            "\tSimilitud: 0.3453\n",
            "\tCategoría: rec.sport.hockey\n",
            "\tTexto: Ottawa picks first, because they had fewer wins during the season, the\n",
            "first tiebreaker.\n",
            "\n",
            "--\n",
            "    Keith Keller\t\t\t\tLET'S GO RANGERS!!!!!\n",
            "\t\t\t\t\t\tLET'S GO QUAKERS!!!!!\n",
            "\tkkeller@mail.sas.upenn.edu\t\tIVY LEAG...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento original N°2498 (Categoría: comp.os.ms-windows.misc):\n",
            "\n",
            "\n",
            "I had this problem when I first loaded windows.  My I/O card is for 2 HD's\n",
            "2 FD's 1 Parrelel 2 serial (1 for mouse and 1 for my external modem) and\n",
            "a game port.  PROBLEM enters.  The DARN serial por...\n",
            "\n",
            "***************** Documentos más similares: ****************\n",
            "\n",
            "DOCUMENTO SIMILAR: 1\n",
            "\n",
            "\tÍndice: 346\n",
            "\tSimilitud: 0.3567\n",
            "\tCategoría: comp.sys.ibm.pc.hardware\n",
            "\tTexto: ] Hi there,\n",
            "] \n",
            "] \n",
            "] : \tI have 1s/1p/1g  I/O card in my 386/40 PC. \n",
            "] : When I plug in wang modem at com4,it works. If I change\n",
            "] : it to com1- it doesn't. \n",
            "] : Program \"chkport\" gives diagnostics like...\n",
            "\n",
            "DOCUMENTO SIMILAR: 2\n",
            "\n",
            "\tÍndice: 3254\n",
            "\tSimilitud: 0.2951\n",
            "\tCategoría: comp.graphics\n",
            "\tTexto: : |> \n",
            ": |>         Is there any way to connect two pointing devices to one serial\n",
            ": |>         port? I haven't tried this but I believe they would interfere\n",
            ": |>         with each other (?) even if on...\n",
            "\n",
            "DOCUMENTO SIMILAR: 3\n",
            "\n",
            "\tÍndice: 5971\n",
            "\tSimilitud: 0.2947\n",
            "\tCategoría: comp.sys.ibm.pc.hardware\n",
            "\tTexto: I have been unable to get COM 4 to work - diagnostic programs such as msd show\n",
            "nothing installed.  I think the software options are OK - is there a known\n",
            "hardware conflict and/or workaround for this p...\n",
            "\n",
            "DOCUMENTO SIMILAR: 4\n",
            "\n",
            "\tÍndice: 6927\n",
            "\tSimilitud: 0.2742\n",
            "\tCategoría: comp.sys.ibm.pc.hardware\n",
            "\tTexto: Is it possible to buy a serial I/O card with the 16550 UART's built in\n",
            "(rather than having to buy them separately, and socketing them in)?\n",
            "\n",
            "My current I/O card uses 8250's (correct number? The brainde...\n",
            "\n",
            "DOCUMENTO SIMILAR: 5\n",
            "\n",
            "\tÍndice: 1782\n",
            "\tSimilitud: 0.2718\n",
            "\tCategoría: comp.os.ms-windows.misc\n",
            "\tTexto: \n",
            "I could never find the Microsoft mouse driver on my Windows 3.1 installation\n",
            "disks, but DOS 6.0 also has version 8.20 of MOUSE.COM.\n",
            "\n",
            "\n",
            "---...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento original N°2047 (Categoría: misc.forsale):\n",
            "\"Computer Friends\" nubus card - good for doing graphics overlays on\n",
            "your videos etc. $275 with apple 8 bit vid card, $225 without. Wont\n",
            "sell vid card separately. UPS (U pay shipping).\n",
            "cheers\n",
            "Mike.\n",
            "...\n",
            "\n",
            "***************** Documentos más similares: ****************\n",
            "\n",
            "DOCUMENTO SIMILAR: 1\n",
            "\n",
            "\tÍndice: 765\n",
            "\tSimilitud: 0.2520\n",
            "\tCategoría: comp.sys.mac.hardware\n",
            "\tTexto: I have a Radius Precision Color 24x video card for the Mac that fits in a \n",
            "NuBus slot.  The card has 3 Mb of VRAM on it, which means that 24-bit color \n",
            "is possible on the card!  The card supports just...\n",
            "\n",
            "DOCUMENTO SIMILAR: 2\n",
            "\n",
            "\tÍndice: 7613\n",
            "\tSimilitud: 0.2418\n",
            "\tCategoría: comp.sys.mac.hardware\n",
            "\tTexto: \n",
            "Apple doesn't make such a card, though I suppose a third party could.  One\n",
            "big problem is that there isn't room for a standard NuBus card inside the\n",
            "LC III.\n",
            "\n",
            "noah...\n",
            "\n",
            "DOCUMENTO SIMILAR: 3\n",
            "\n",
            "\tÍndice: 1083\n",
            "\tSimilitud: 0.2193\n",
            "\tCategoría: comp.os.ms-windows.misc\n",
            "\tTexto: I have heard many things about the ATI Ultra Pro card. Some have\n",
            "been positive but most are negative. Could people please confirm\n",
            "these?  (I am interested in the EISA version in particular).\n",
            "\n",
            "1) The c...\n",
            "\n",
            "DOCUMENTO SIMILAR: 4\n",
            "\n",
            "\tÍndice: 8141\n",
            "\tSimilitud: 0.2116\n",
            "\tCategoría: sci.electronics\n",
            "\tTexto: I recently bought an apparantly complete Expansion Chassis by Mountain\n",
            "Computer Inc.  It consists of a box with 8 Apple ][+ compatible slots,\n",
            "powersupply brick, interface card and ribbon cable to atta...\n",
            "\n",
            "DOCUMENTO SIMILAR: 5\n",
            "\n",
            "\tÍndice: 11283\n",
            "\tSimilitud: 0.1980\n",
            "\tCategoría: comp.os.ms-windows.misc\n",
            "\tTexto: I have the local bus card also, and don't have any such problems with it\n",
            "now, but this is the second card I've gotten - the first card didn't work\n",
            "in VGA mode correctly.  Maybe they still have some qu...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento original N°425 (Categoría: sci.electronics):\n",
            "Hi,\n",
            "\n",
            "Right now I should do some characterization of opamps. Because I don't  \n",
            "have\n",
            "special equipment for this task, I have to do this job with relativly  \n",
            "simple\n",
            "equipments (Frequency sweeper, DSO, et...\n",
            "\n",
            "***************** Documentos más similares: ****************\n",
            "\n",
            "DOCUMENTO SIMILAR: 1\n",
            "\n",
            "\tÍndice: 5571\n",
            "\tSimilitud: 0.1306\n",
            "\tCategoría: misc.forsale\n",
            "\tTexto: This is a test. Thanks.\n",
            "...\n",
            "\n",
            "DOCUMENTO SIMILAR: 2\n",
            "\n",
            "\tÍndice: 428\n",
            "\tSimilitud: 0.1086\n",
            "\tCategoría: comp.sys.mac.hardware\n",
            "\tTexto: this is a test\n",
            " \n",
            "...\n",
            "\n",
            "DOCUMENTO SIMILAR: 3\n",
            "\n",
            "\tÍndice: 3140\n",
            "\tSimilitud: 0.1086\n",
            "\tCategoría: comp.sys.mac.hardware\n",
            "\tTexto: this is a test\n",
            "\n",
            "-- \n",
            "****************************************************************************\n",
            "...\n",
            "\n",
            "DOCUMENTO SIMILAR: 4\n",
            "\n",
            "\tÍndice: 9266\n",
            "\tSimilitud: 0.1086\n",
            "\tCategoría: rec.motorcycles\n",
            "\tTexto: \n",
            "test\n",
            "...\n",
            "\n",
            "DOCUMENTO SIMILAR: 5\n",
            "\n",
            "\tÍndice: 7811\n",
            "\tSimilitud: 0.1072\n",
            "\tCategoría: comp.sys.ibm.pc.hardware\n",
            "\tTexto: Hi netters!\n",
            "\tI'm looking for books that showing how to fix your own hardware problem.\n",
            "\tPlease let me know if you have any books in mind.  Thanks.\n",
            "...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Documento original N°6255 (Categoría: comp.graphics):\n",
            "Has anybody compiled VOGL-graphics library\n",
            "for IBM-PC? I need to call it from MS-Fortran\n",
            "but don't have MS-C to compile the sources.\n",
            "\n",
            "Thanks for any help...\n",
            "...\n",
            "\n",
            "***************** Documentos más similares: ****************\n",
            "\n",
            "DOCUMENTO SIMILAR: 1\n",
            "\n",
            "\tÍndice: 8270\n",
            "\tSimilitud: 0.3771\n",
            "\tCategoría: comp.os.ms-windows.misc\n",
            "\tTexto: Hi!  I will like to know if there is a FORTRAN library for MS-Windows v3+ out\n",
            "there.\n",
            "\n",
            "I have several lots of source code written by past A/Ps in MS-FORTRAN, and\n",
            "recently have needed to port them to MS...\n",
            "\n",
            "DOCUMENTO SIMILAR: 2\n",
            "\n",
            "\tÍndice: 10511\n",
            "\tSimilitud: 0.2546\n",
            "\tCategoría: comp.graphics\n",
            "\tTexto: \n",
            "You probably need an X server running on top of MS DOS.  I use Desqview/X\n",
            "but any MS-DOS X server should do.\n",
            "\n",
            "-- ...\n",
            "\n",
            "DOCUMENTO SIMILAR: 3\n",
            "\n",
            "\tÍndice: 10078\n",
            "\tSimilitud: 0.2370\n",
            "\tCategoría: rec.motorcycles\n",
            "\tTexto: azw>Weight and size over rough roads is a definite no-no. If is starts to\n",
            "azw>drift, you aint going to catch it.\n",
            "\n",
            "mrb>If you're riding hard enough for this to be of concern, then yes, a\n",
            "mrb>lighter bi...\n",
            "\n",
            "DOCUMENTO SIMILAR: 4\n",
            "\n",
            "\tÍndice: 7139\n",
            "\tSimilitud: 0.2290\n",
            "\tCategoría: talk.politics.misc\n",
            "\tTexto: THE WHITE HOUSE\n",
            "\n",
            "                    Office of the Press Secretary\n",
            "_____________________________________________________________________\n",
            "For Immediate Release                                  April 15...\n",
            "\n",
            "DOCUMENTO SIMILAR: 5\n",
            "\n",
            "\tÍndice: 9858\n",
            "\tSimilitud: 0.2205\n",
            "\tCategoría: comp.os.ms-windows.misc\n",
            "\tTexto: Hi! I was wondering if anyone out there could help me.\n",
            "I have an error message that goes:\n",
            "\n",
            "\n",
            "\n",
            "What does it mean?\n",
            "\n",
            "I am running MS windows 3.1.\n",
            "\n",
            "Thanks in advance...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "i=1\n",
        "for doc_idx, info in resultados.items():\n",
        "    print(f\"\\nDocumento original N°{doc_idx} (Categoría: {info['categoria']}):\")\n",
        "    print(info['documento_original'])\n",
        "    print(\"\\n***************** Documentos más similares: ****************\")\n",
        "    for doc in info['documentos_similares']:\n",
        "        print(f\"\\nDOCUMENTO SIMILAR: {i}\")\n",
        "        print(f\"\\n\\tÍndice: {doc['indice']}\")\n",
        "        print(f\"\\tSimilitud: {doc['similitud']:.4f}\")\n",
        "        print(f\"\\tCategoría: {doc['categoria']}\")\n",
        "        print(f\"\\tTexto: {doc['texto']}\")\n",
        "        i+=1\n",
        "    print(\"-\" * 80)\n",
        "    i=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resumen del punto 1:\n",
        "\n",
        "Documento N°1:\n",
        "\tTema: rec.sport.hockey\n",
        "\n",
        "Documentos similares:  \n",
        "1- Índice: 9434  \n",
        "   Similitud: 0.3907  \n",
        "   Categoría: rec.sport.baseball  \n",
        "2- Índice: 10511  \n",
        "   Similitud: 0.2546  \n",
        "   Categoría: comp.graphics  \n",
        "3- Índice: 10078  \n",
        "   Similitud: 0.2370  \n",
        "   Categoría: rec.motorcycles  \n",
        "4- Índice: 7139  \n",
        "   Similitud: 0.2290  \n",
        "   Categoría: talk.politics.misc  \n",
        "5- Índice: 9858  \n",
        "   Similitud: 0.2205  \n",
        "   Categoría: comp.os.ms-windows.misc  \n",
        "   \n",
        "   \n",
        "Documento N°2:\n",
        "\tTema: comp.os.ms-windows.misc\n",
        "\t\n",
        "Documentos similares:  \n",
        "1-  Índice: 346  \n",
        "\tSimilitud: 0.3567  \n",
        "\tCategoría: comp.sys.ibm.pc.hardware  \n",
        "2-  Índice: 3254  \n",
        "\tSimilitud: 0.2951  \n",
        "\tCategoría: comp.graphics  \n",
        "3- \tÍndice: 5971  \n",
        "\tSimilitud: 0.2947  \n",
        "\tCategoría: comp.sys.ibm.pc.hardware  \n",
        "4- \tÍndice: 6927  \n",
        "\tSimilitud: 0.2742\n",
        "\tCategoría: comp.sys.ibm.pc.hardware  \n",
        "5- \tÍndice: 1782  \n",
        "\tSimilitud: 0.2718  \n",
        "\tCategoría: comp.os.ms-windows.misc  \n",
        "\t\n",
        "\t\n",
        "Documento N°3:\n",
        "\tTema: misc.forsale\t\n",
        "\n",
        "1-  Índice: 765  \n",
        "\tSimilitud: 0.2520  \n",
        "\tCategoría: comp.sys.mac.hardware  \n",
        "2-  Índice: 7613  \n",
        "\tSimilitud: 0.2418  \n",
        "\tCategoría: comp.sys.mac.hardware  \n",
        "3-  Índice: 1083  \n",
        "\tSimilitud: 0.2193  \n",
        "\tCategoría: comp.os.ms-windows.misc  \n",
        "4-  Índice: 8141  \n",
        "\tSimilitud: 0.2116  \n",
        "\tCategoría: sci.electronics  \n",
        "5-  Índice: 11283  \n",
        "\tSimilitud: 0.1980  \n",
        "\tCategoría: comp.os.ms-windows.misc  \n",
        "\n",
        "\n",
        "Documento N°4:\n",
        "\tTema: sci.electronics\n",
        "\n",
        "1- Índice: 5571  \n",
        "\tSimilitud: 0.1306  \n",
        "\tCategoría: misc.forsale  \n",
        "2- \tÍndice: 428  \n",
        "\tSimilitud: 0.1086  \n",
        "\tCategoría: comp.sys.mac.hardware  \n",
        "3- \tÍndice: 3140  \n",
        "\tSimilitud: 0.1086  \n",
        "\tCategoría: comp.sys.mac.hardware  \n",
        "4- \tÍndice: 9266  \n",
        "\tSimilitud: 0.1086  \n",
        "\tCategoría: rec.motorcycles  \n",
        "5- \tÍndice: 7811  \n",
        "\tSimilitud: 0.1072  \n",
        "\tCategoría: comp.sys.ibm.pc.hardware  \n",
        "\t\n",
        "Documento N°5:\n",
        "\tTema: comp.graphics\n",
        "\t\n",
        "1-  Índice: 8270  \n",
        "\tSimilitud: 0.3771  \n",
        "\tCategoría: comp.os.ms-windows.misc  \n",
        "2-  Índice: 10511  \n",
        "\tSimilitud: 0.2546  \n",
        "\tCategoría: comp.graphics  \n",
        "3-  Índice: 10078  \n",
        "\tSimilitud: 0.2370  \n",
        "\tCategoría: rec.motorcycles  \n",
        "4-  Índice: 7139  \n",
        "\tSimilitud: 0.2290  \n",
        "\tCategoría: talk.politics.misc  \n",
        "5-  Índice: 9858  \n",
        "\tSimilitud: 0.2205  \n",
        "\tCategoría: comp.os.ms-windows.misc  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2**. Entrenar modelos de clasificación Naïve Bayes para maximizar el desempeño de clasificación\n",
        "(f1-score macro) en el conjunto de datos de test. Considerar cambiar parámteros\n",
        "de instanciación del vectorizador y los modelos y probar modelos de Naïve Bayes Multinomial\n",
        "y ComplementNB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "\n",
        "def entrenar_y_evaluar_modelos(X_train, y_train, X_test, y_test):\n",
        "\n",
        "    # Pipelines para cada tipo de modelo\n",
        "    pipeline_mnb = Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer()),\n",
        "        ('classifier', MultinomialNB())\n",
        "    ])\n",
        "\n",
        "    pipeline_cnb = Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer()),\n",
        "        ('classifier', ComplementNB())\n",
        "    ])\n",
        "\n",
        "    # Set de parámetros para rpobar con GridSesarch \n",
        "    parametros = {\n",
        "        'vectorizer__max_features': [None, 10000, 50000], # Prueba con todaslas palabras, con las 10000 mas frecuentes o con las 50000 mas frecuentes\n",
        "        'vectorizer__ngram_range': [(1,1), (1,2)], # Pureba con unigramas y bigramas\n",
        "        'vectorizer__min_df': [1, 2, 5], # Ignora términos que tenga un porcentaje de ocurrencia menor a este\n",
        "        'vectorizer__max_df': [0.95, 0.9, 0.8], # Ignora términos que tenga un porcentaje de ocurrencia mayor a este\n",
        "    }\n",
        "\n",
        "    # Entrena modelos\n",
        "    resultados = {}\n",
        "    for nombre, pipeline in [('MultinomialNB', pipeline_mnb), ('ComplementNB', pipeline_cnb)]:\n",
        "        print(f\"\\nEntrenando {nombre}...\")\n",
        "        \n",
        "        # Búsqueda de mejores parámetros usando validación cruzada\n",
        "        grid_search = GridSearchCV(\n",
        "            pipeline,\n",
        "            parametros,\n",
        "            cv=5,\n",
        "            scoring='f1_macro',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        grid_search.fit(X_train, y_train)\n",
        "        \n",
        "        # Resultados\n",
        "        resultados[nombre] = {\n",
        "            'mejor_score_cv': grid_search.best_score_,\n",
        "            'mejores_params': grid_search.best_params_,\n",
        "            'mejor_modelo': grid_search.best_estimator_\n",
        "        }\n",
        "        \n",
        "        # Evaluamos en conjunto de test\n",
        "        y_pred = grid_search.predict(X_test)\n",
        "        f1 = f1_score(y_test, y_pred, average='macro')\n",
        "        \n",
        "        print(f\"\\nMejores parámetros para {nombre}:\")\n",
        "        print(grid_search.best_params_)\n",
        "        print(f\"\\nF1-score (macro) en validación cruzada: {grid_search.best_score_:.4f}\")\n",
        "        print(f\"F1-score (macro) en test: {f1:.4f}\")\n",
        "        print(\"\\nReporte de clasificación detallado:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        \n",
        "    return resultados\n",
        "\n",
        "def analizar_errores(modelo, X_test, y_test, target_names):\n",
        "\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    \n",
        "    # Encontrar ejemplos mal clasificados\n",
        "    errores_indices = np.where(y_pred != y_test)[0]\n",
        "    \n",
        "    errores_analisis = []\n",
        "    for idx in errores_indices[:10]:  # Analizamos los primeros 10 errores\n",
        "        errores_analisis.append({\n",
        "            'texto': X_test[idx][:200] + \"...\",  # Primeros 200 caracteres\n",
        "            'categoria_real': target_names[y_test[idx]],\n",
        "            'categoria_predicha': target_names[y_pred[idx]],\n",
        "            'probabilidades': modelo.predict_proba([X_test[idx]])[0]\n",
        "        })\n",
        "    \n",
        "    return errores_analisis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Entrenando MultinomialNB...\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "\n",
            "Mejores parámetros para MultinomialNB:\n",
            "{'vectorizer__max_df': 0.8, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}\n",
            "\n",
            "F1-score (macro) en validación cruzada: 0.6533\n",
            "F1-score (macro) en test: 0.6182\n",
            "\n",
            "Reporte de clasificación detallado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.15      0.25       319\n",
            "           1       0.64      0.67      0.66       389\n",
            "           2       0.66      0.55      0.60       394\n",
            "           3       0.57      0.72      0.64       392\n",
            "           4       0.77      0.61      0.68       385\n",
            "           5       0.79      0.75      0.77       395\n",
            "           6       0.82      0.74      0.78       390\n",
            "           7       0.76      0.70      0.73       396\n",
            "           8       0.81      0.73      0.77       398\n",
            "           9       0.90      0.76      0.82       397\n",
            "          10       0.58      0.89      0.70       399\n",
            "          11       0.65      0.75      0.69       396\n",
            "          12       0.67      0.48      0.56       393\n",
            "          13       0.78      0.73      0.75       396\n",
            "          14       0.79      0.68      0.73       394\n",
            "          15       0.30      0.92      0.46       398\n",
            "          16       0.58      0.68      0.62       364\n",
            "          17       0.80      0.74      0.77       376\n",
            "          18       0.86      0.23      0.37       310\n",
            "          19       0.67      0.01      0.02       251\n",
            "\n",
            "    accuracy                           0.65      7532\n",
            "   macro avg       0.70      0.63      0.62      7532\n",
            "weighted avg       0.70      0.65      0.64      7532\n",
            "\n",
            "\n",
            "Entrenando ComplementNB...\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "\n",
            "Mejores parámetros para ComplementNB:\n",
            "{'vectorizer__max_df': 0.8, 'vectorizer__max_features': 50000, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 1)}\n",
            "\n",
            "F1-score (macro) en validación cruzada: 0.7535\n",
            "F1-score (macro) en test: 0.6933\n",
            "\n",
            "Reporte de clasificación detallado:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.43      0.36       319\n",
            "           1       0.71      0.72      0.72       389\n",
            "           2       0.70      0.61      0.65       394\n",
            "           3       0.64      0.71      0.67       392\n",
            "           4       0.77      0.72      0.75       385\n",
            "           5       0.82      0.78      0.80       395\n",
            "           6       0.76      0.75      0.76       390\n",
            "           7       0.81      0.74      0.77       396\n",
            "           8       0.84      0.78      0.81       398\n",
            "           9       0.92      0.84      0.88       397\n",
            "          10       0.86      0.93      0.89       399\n",
            "          11       0.74      0.80      0.77       396\n",
            "          12       0.71      0.55      0.62       393\n",
            "          13       0.82      0.81      0.81       396\n",
            "          14       0.80      0.79      0.80       394\n",
            "          15       0.51      0.90      0.65       398\n",
            "          16       0.59      0.74      0.65       364\n",
            "          17       0.82      0.84      0.83       376\n",
            "          18       0.67      0.41      0.51       310\n",
            "          19       0.53      0.10      0.16       251\n",
            "\n",
            "    accuracy                           0.71      7532\n",
            "   macro avg       0.72      0.70      0.69      7532\n",
            "weighted avg       0.73      0.71      0.71      7532\n",
            "\n",
            "\n",
            "Análisis de errores para el mejor modelo (ComplementNB):\n",
            "\n",
            "Error #1\n",
            "Texto: I am a little confused on all of the models of the 88-89 bonnevilles.\n",
            "I have heard of the LE SE LSE SSE SSEI. Could someone tell me the\n",
            "differences are far as features or performance. I am also curiou...\n",
            "Categoría real: rec.autos\n",
            "Categoría predicha: comp.sys.mac.hardware\n",
            "Top 3 probabilidades:\n",
            "- comp.sys.mac.hardware: 0.0631\n",
            "- rec.autos: 0.0597\n",
            "- rec.sport.baseball: 0.0565\n",
            "\n",
            "Error #2\n",
            "Texto: I'm not familiar at all with the format of these \"X-Face:\" thingies, but\n",
            "after seeing them in some folks' headers, I've *got* to *see* them (and\n",
            "maybe make one of my own)!\n",
            "\n",
            "I've got \"dpg-view\" on my L...\n",
            "Categoría real: comp.windows.x\n",
            "Categoría predicha: comp.graphics\n",
            "Top 3 probabilidades:\n",
            "- comp.graphics: 0.0692\n",
            "- comp.windows.x: 0.0638\n",
            "- comp.sys.ibm.pc.hardware: 0.0522\n",
            "\n",
            "Error #3\n",
            "Texto: \n",
            "In a word, yes.\n",
            "...\n",
            "Categoría real: alt.atheism\n",
            "Categoría predicha: soc.religion.christian\n",
            "Top 3 probabilidades:\n",
            "- soc.religion.christian: 0.0560\n",
            "- talk.religion.misc: 0.0533\n",
            "- alt.atheism: 0.0525\n",
            "\n",
            "Error #4\n",
            "Texto: \n",
            "I've just spent two solid months arguing that no such thing as an\n",
            "objective moral system exists....\n",
            "Categoría real: talk.religion.misc\n",
            "Categoría predicha: alt.atheism\n",
            "Top 3 probabilidades:\n",
            "- alt.atheism: 0.0705\n",
            "- talk.religion.misc: 0.0628\n",
            "- soc.religion.christian: 0.0522\n",
            "\n",
            "Error #5\n",
            "Texto: A friend of mine managed to get a copy of a computerised Greek and Hebrew \n",
            "Lexicon called \"The Word Perfect\" (That is not the word processing \n",
            "package WordPerfect). However, some one wiped out the EXE...\n",
            "Categoría real: soc.religion.christian\n",
            "Categoría predicha: comp.os.ms-windows.misc\n",
            "Top 3 probabilidades:\n",
            "- comp.os.ms-windows.misc: 0.0671\n",
            "- talk.politics.mideast: 0.0557\n",
            "- comp.graphics: 0.0556\n",
            "\n",
            "Error #6\n",
            "Texto: \n",
            "Probably because it IS rape.\n",
            "\n",
            "\n",
            "So nothing.  It may work for some, but not for others: it doesn't give any\n",
            "insight into an overall God or overall truth of a religion- it would seem to be\n",
            "dependent sol...\n",
            "Categoría real: alt.atheism\n",
            "Categoría predicha: soc.religion.christian\n",
            "Top 3 probabilidades:\n",
            "- soc.religion.christian: 0.1194\n",
            "- alt.atheism: 0.0699\n",
            "- talk.religion.misc: 0.0598\n",
            "\n",
            "Error #7\n",
            "Texto: From article <C68uBG.K2w@world.std.com>, by cfw@world.std.com (Christopher F Wroten):\n",
            "Good question.\n",
            "Answer: The EISA bus does move 32 bits rather than ISA's 8/(16?)\n",
            "        But it still moves it at a...\n",
            "Categoría real: comp.os.ms-windows.misc\n",
            "Categoría predicha: comp.sys.ibm.pc.hardware\n",
            "Top 3 probabilidades:\n",
            "- comp.sys.ibm.pc.hardware: 0.2111\n",
            "- comp.sys.mac.hardware: 0.0594\n",
            "- comp.os.ms-windows.misc: 0.0497\n",
            "\n",
            "Error #8\n",
            "Texto: Hello,\n",
            "i'm interested in those devices too.\n",
            "Could also send me your suggestions.\n",
            "Thank in advance.\n",
            "Regards.\n",
            "-- ...\n",
            "Categoría real: comp.graphics\n",
            "Categoría predicha: comp.sys.ibm.pc.hardware\n",
            "Top 3 probabilidades:\n",
            "- comp.sys.ibm.pc.hardware: 0.0599\n",
            "- comp.graphics: 0.0585\n",
            "- sci.electronics: 0.0566\n",
            "\n",
            "Error #9\n",
            "Texto: This is an invitation to send articles to the Informatica magazine.\n",
            "The first fully international issue has been published and echoes \n",
            "are quite favourable. For any information, contact (matjaz.gams@i...\n",
            "Categoría real: comp.graphics\n",
            "Categoría predicha: soc.religion.christian\n",
            "Top 3 probabilidades:\n",
            "- soc.religion.christian: 0.0643\n",
            "- talk.politics.mideast: 0.0619\n",
            "- sci.crypt: 0.0572\n",
            "\n",
            "Error #10\n",
            "Texto: \n",
            "\n",
            "I don't know about Canada, but I have heard from people\n",
            "doing translation work in Papua New Quinea, that they\n",
            "like them and have had good response on service.\n",
            "\n",
            "Another is seriously considering buyin...\n",
            "Categoría real: comp.sys.ibm.pc.hardware\n",
            "Categoría predicha: soc.religion.christian\n",
            "Top 3 probabilidades:\n",
            "- soc.religion.christian: 0.0547\n",
            "- rec.autos: 0.0546\n",
            "- talk.politics.misc: 0.0522\n"
          ]
        }
      ],
      "source": [
        "# Entrenamos y evaluamos los modelos\n",
        "resultados = entrenar_y_evaluar_modelos(\n",
        "    newsgroups_train.data,\n",
        "    newsgroups_train.target,\n",
        "    newsgroups_test.data,\n",
        "    newsgroups_test.target\n",
        ")\n",
        "\n",
        "# Analizamos los errores del mejor modelo\n",
        "mejor_modelo = max(resultados.items(), key=lambda x: x[1]['mejor_score_cv'])\n",
        "print(f\"\\nAnálisis de errores para el mejor modelo ({mejor_modelo[0]}):\")\n",
        "errores = analizar_errores(\n",
        "    mejor_modelo[1]['mejor_modelo'],\n",
        "    newsgroups_test.data,\n",
        "    newsgroups_test.target,\n",
        "    newsgroups_test.target_names\n",
        ")\n",
        "\n",
        "# Mostramos algunos ejemplos de errores\n",
        "for i, error in enumerate(errores, 1):\n",
        "    print(f\"\\nError #{i}\")\n",
        "    print(f\"Texto: {error['texto']}\")\n",
        "    print(f\"Categoría real: {error['categoria_real']}\")\n",
        "    print(f\"Categoría predicha: {error['categoria_predicha']}\")\n",
        "    print(\"Top 3 probabilidades:\")\n",
        "    probs_ordenadas = sorted(enumerate(error['probabilidades']), key=lambda x: x[1], reverse=True)[:3]\n",
        "    for idx, prob in probs_ordenadas:\n",
        "        print(f\"- {newsgroups_test.target_names[idx]}: {prob:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen:\n",
        "\n",
        "Modelo: MultinomialNB\n",
        "\n",
        "Mejores parámetros\n",
        "'vectorizer__max_df': 0.8, 'vectorizer__max_features': 10000, 'vectorizer__min_df': 5, 'vectorizer__ngram_range': (1, 1)}\n",
        "\n",
        "Iterpretación:\n",
        "'vectorizer__max_df': 0.8 ==> Se eliminan las palabras muy frecuentes. Debe ser porque si se repiten tanto, no deben ser tan importantes\n",
        "'vectorizer__min_df': 5 ==> Se eliminan las palabras que tienen poca repitencia.\n",
        "'vectorizer__max_features': 10000 ==> Prueba con las 10000 mas frecuentes\n",
        "'vectorizer__ngram_range': (1, 1) ==> La mejor opcion es con unigramas. Parece que permite desmenusar mejor las palabras\n",
        "\n",
        "F1-score (macro) en validación cruzada: 0.6533\n",
        "F1-score (macro) en test: 0.6182\n",
        "\n",
        "El modelo tiene algo de overfiting, ya que la métrica de validación tiene un valor inferior a la test\n",
        "\n",
        "-------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "Modelo: ComplementNB\n",
        "\n",
        "Mejores parámetros\n",
        "{'vectorizer__max_df': 0.8, 'vectorizer__max_features': 50000, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 1)}\n",
        "\n",
        "Iterpretación:\n",
        "'vectorizer__max_df': 0.8 ==> Se eliminan las palabras muy frecuentes. Debe ser porque si se repiten tanto, no deben ser tan importantes\n",
        "'vectorizer__min_df': 1 ==> Se eliminan las palabras que tienen poca repitencia. En este caso es mas estricto que el modelo MultinomialNB\n",
        "'vectorizer__max_features': 50000 ==> Prueba con las 50000 mas frecuentes\n",
        "'vectorizer__ngram_range': (1, 1) ==> La mejor opcion es con unigramas. Parece que permite desmenusar mejor las palabras\n",
        "\n",
        "F1-score (macro) en validación cruzada: 0.7535\n",
        "F1-score (macro) en test: 0.6933\n",
        "\n",
        "El modelo performa mejor que MultinomialNB, pero se observa tambien overfiting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3**. Transponer la matriz documento-término. De esa manera se obtiene una matriz\n",
        "término-documento que puede ser interpretada como una colección de vectorización de palabras.\n",
        "Estudiar ahora similaridad entre palabras tomando 5 palabras y estudiando sus 5 más similares. **La elección de palabras no debe ser al azar para evitar la aparición de términos poco interpretables, elegirlas \"manualmente\"**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Palabra: science\n",
            "- scientific: 0.3336\n",
            "- empirical: 0.2737\n",
            "- hypotheses: 0.1890\n",
            "- fiction: 0.1842\n",
            "- scientists: 0.1781\n",
            "\n",
            "Palabra: tree\n",
            "- immaculate: 0.2701\n",
            "- righteous: 0.2575\n",
            "- palm: 0.2472\n",
            "- u2: 0.2131\n",
            "- christmas: 0.2078\n",
            "\n",
            "Palabra: clothes\n",
            "- whites: 0.3479\n",
            "- cramer: 0.2502\n",
            "- coat: 0.2463\n",
            "- clothing: 0.2445\n",
            "- substitute: 0.2373\n",
            "\n",
            "Palabra: vacation\n",
            "- las: 0.3774\n",
            "- orlando: 0.2984\n",
            "- vegas: 0.2732\n",
            "- hotel: 0.2666\n",
            "- trip: 0.2333\n",
            "\n",
            "Palabra: electronics\n",
            "- 805: 0.1738\n",
            "- addressed: 0.1646\n",
            "- diagram: 0.1627\n",
            "- mq: 0.1520\n",
            "- females: 0.1477\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def analizar_similitud_palabras(newsgroups_train, palabras_interes):\n",
        "\n",
        "    # Se instancia un vectorizador TfidfVectorizer conb los hiperparámetros obtenidos en el punto anterior\n",
        "    vectorizer = TfidfVectorizer(max_df=0.8, min_df=5, max_features=10000    )\n",
        "    \n",
        "    # Matriz documento-término\n",
        "    X = vectorizer.fit_transform(newsgroups_train.data)\n",
        "    \n",
        "    # Obtenemos el vocabulario y la matriz transpuesta (término-documento)\n",
        "    vocabulary = vectorizer.get_feature_names_out()\n",
        "    X_transpuesta = X.T\n",
        "    \n",
        "    # Verificamos que las palabras de interés estén en el vocabulario\n",
        "    palabras_validas = [palabra for palabra in palabras_interes if palabra in vectorizer.vocabulary_]\n",
        "    palabras_no_encontradas = set(palabras_interes) - set(palabras_validas)\n",
        "    \n",
        "    if palabras_no_encontradas:\n",
        "        print(f\"Advertencia: Las siguientes palabras no se encontraron en el vocabulario: {palabras_no_encontradas}\")\n",
        "    \n",
        "    resultados = {}\n",
        "    \n",
        "    for palabra in palabras_validas:\n",
        "        # Obtenemos el índice de la palabra en el vocabulario\n",
        "        idx_palabra = vectorizer.vocabulary_[palabra]\n",
        "        \n",
        "        # Calculamos similitud con todas las demás palabras\n",
        "        vector_palabra = X_transpuesta[idx_palabra].toarray()\n",
        "        similitudes = cosine_similarity(vector_palabra, X_transpuesta.toarray())[0]\n",
        "        \n",
        "        # Ordenamos las palabras por similitud (excluyendo la palabra misma)\n",
        "        similitudes[idx_palabra] = -1\n",
        "        indices_top = similitudes.argsort()[::-1][:5]\n",
        "        \n",
        "        # Guardamos las palabras más similares y sus puntajes\n",
        "        palabras_similares = [\n",
        "            (vocabulary[idx], similitudes[idx])\n",
        "            for idx in indices_top\n",
        "        ]\n",
        "        \n",
        "        resultados[palabra] = palabras_similares\n",
        "        \n",
        "        # Imprimimos los resultados\n",
        "        print(f\"\\nPalabra: {palabra}\")\n",
        "        for palabra_similar, score in palabras_similares:\n",
        "            print(f\"- {palabra_similar}: {score:.4f}\")\n",
        "    \n",
        "    return resultados\n",
        "\n",
        "# Lista de palabras elegidas manualmente. Como el diccionario está en inglés, las palabras se colocan en inglés.\n",
        "palabras_interes = ['science', 'tree', 'clothes','vacation','electronics']\n",
        "\n",
        "# Ejecutamos el análisis\n",
        "resultados = analizar_similitud_palabras(newsgroups_train, palabras_interes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resumen:\n",
        "\n",
        "Las palabras elegidas fueron: science, tree, clothes, vacation, electronics\n",
        "\n",
        "\n",
        "Palabra: science\n",
        "Las 5 más similares:  \n",
        "- scientific: 0.3336  \n",
        "- empirical: 0.2737  \n",
        "- hypotheses: 0.1890  \n",
        "- fiction: 0.1842  \n",
        "- scientists: 0.1781  \n",
        "\n",
        "Observaciones: Todas las palabras tienen alta relación con la palabra buscada\n",
        "\n",
        "Palabra: tree  \n",
        "Las 5 más similares:  \n",
        "- immaculate: 0.2701  \n",
        "- righteous: 0.2575  \n",
        "- palm: 0.2472  \n",
        "- u2: 0.2131  \n",
        "- christmas: 0.2078  \n",
        "\n",
        "Observaciones: Acá se ve confusión.    \n",
        "\timmaculate - No sé que relación encuentra    \n",
        "\trighteous - No sé que relación encuentra    \n",
        "\tpalm - Palmera, es una variedad de árbol    \n",
        "\tu2 - Supongo que la banda musical. No sé que relación encuentra    \n",
        "\tchristmas - Relacionada por àrbol de navidad    \n",
        "\n",
        "Palabra: clothes  \n",
        "Las 5 más similares:  \n",
        "- whites: 0.3479  \n",
        "- cramer: 0.2502  \n",
        "- coat: 0.2463  \n",
        "- clothing: 0.2445  \n",
        "- substitute: 0.2373  \n",
        "\n",
        "Observaciones: Algunas bien, algunas mal  \n",
        "\twhites - (BLancas) Tiene relación con la palabra ropa  \n",
        "\tcramer - No se que significa  \n",
        "\tcoat - Campera/abrigo, tiene relación  \n",
        "\tclothing - Sinónimo de ropa  \n",
        "\tsubstitute - No sé que relación encuentra  \n",
        "\n",
        "Palabra: vacation  \n",
        "Las 5 más similares:  \n",
        "- las: 0.3774  \n",
        "- orlando: 0.2984  \n",
        "- vegas: 0.2732  \n",
        "- hotel: 0.2666  \n",
        "- trip: 0.2333  \n",
        "\n",
        "Observaciones: \tAlgunas bien, algunas mal  \n",
        "\tlas: Supongo que lo relaciona con Las Vegas, esta bien pero corta la palabra  \n",
        "\torlando: Correcto  \n",
        "\tvegas: Supongo que lo relaciona con Las Vegas, esta bien pero corta la palabra  \n",
        "\thotel: Correcto  \n",
        "\ttrip: Correcto  \n",
        "\n",
        "Palabra: electronics  \n",
        "Las 5 más similares:  \n",
        "- 805: 0.1738  \n",
        "- addressed: 0.1646  \n",
        "- diagram: 0.1627  \n",
        "- mq: 0.1520  \n",
        "- females: 0.1477  \n",
        "\n",
        "Observaciones: \tAlgunas bien, algunas mal  \n",
        "\n",
        "\t805: No sé que relación encuentra  \n",
        "\taddressed: Tiene relación  \n",
        "\tdiagram: Tiene relación  \n",
        "\tmq: No sé que significa \"mq\"   \n",
        "\tfemales: No sé que relación encuentra  \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
